{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD truncated for space matrix:\n",
    "http://scikit-learn.org/stable/modules/decomposition.html\n",
    "FE ideas:\n",
    "https://www.kaggle.com/visnaga/two-sigma-connect-rental-listing-inquiries/xgboost-for-the-millionth-time-0-54724-lb/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-02-26 \n",
      "\n",
      "CPython 3.5.1\n",
      "IPython 4.2.0\n",
      "\n",
      "numpy 1.12.0\n",
      "pandas 0.18.1\n",
      "matplotlib 2.0.0\n",
      "scikit-learn 0.18.1\n",
      "seaborn 0.7.1\n",
      "\n",
      "compiler   : MSC v.1900 64 bit (AMD64)\n",
      "system     : Windows\n",
      "release    : 7\n",
      "machine    : AMD64\n",
      "processor  : Intel64 Family 6 Model 58 Stepping 9, GenuineIntel\n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -d -v -m -p numpy,pandas,matplotlib,scikit-learn,seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "   \n",
    "class fe (BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Custom tranformer that selects numerical featues (attribute names)\n",
    "       and feature engineer to retunr attribute names plus new featues\"\"\"\n",
    "    \n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        # selection\n",
    "        X = X[self.attribute_names]\n",
    "        # feature engineering\n",
    "        X[\"bed_bath_ration\"] = X[\"bedrooms\"]/X[\"bathrooms\"] # ratio rooms\n",
    "        X[\"bed_bath_ration\"] = X[\"bed_bath_ration\"].map(lambda x: 100 if x>100 else x) # fix inf\n",
    "        X[\"bed_bath_ration\"].fillna(value=-1,inplace=True) # fix na\n",
    "        \n",
    "        X[\"room_dif\"] = X[\"bedrooms\"] - X[\"bathrooms\"] \n",
    "        \n",
    "        X[\"total_rooms\"] = X[\"bedrooms\"] + X[\"bathrooms\"]  # total rooms\n",
    "        \n",
    "        X['half_bath'] = X['bathrooms'].map(lambda x: 1 if x%1 == 0.5 else 0) # halfbath\n",
    "        \n",
    "        X[\"number_features\"] = X[\"features\"].map(lambda x: len(x)) # total features\n",
    "        \n",
    "        X[\"number_photos\"] = X[\"photos\"].map(lambda x: len(x)) # total features\n",
    "        \n",
    "        X[\"num_description_words\"] = X[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
    "        \n",
    "        X[\"ratio_rooms_photos\"] = X[\"total_rooms\"]/X[\"number_photos\"]\n",
    "        X[\"ratio_rooms_photos\"] = X[\"ratio_rooms_photos\"].map(lambda x: 100 if x>100 else x) # fix inf\n",
    "        X[\"ratio_rooms_photos\"].fillna(value=-1,inplace=True) # fix na\n",
    "        \n",
    "        X[\"price_per_room\"] = X[\"price\"]/X[\"total_rooms\"]\n",
    "        X[\"price_per_room\"] = X[\"price_per_room\"].map(lambda x: 100 if x>100 else x) # fix inf\n",
    "        X[\"price_per_room\"].fillna(value=-1,inplace=True) # fix na\n",
    "        \n",
    "        X[\"price_per_bedroom\"] = X[\"price\"]/X[\"bedrooms\"]\n",
    "        X[\"price_per_bedroom\"] = X[\"price_per_bedroom\"].map(lambda x: 100 if x>100 else x) # fix inf\n",
    "        X[\"price_per_bedroom\"].fillna(value=-1,inplace=True) # fix na\n",
    "        \n",
    "        X[\"price_per_bathroom\"] = X[\"price\"]/X[\"bathrooms\"]\n",
    "        X[\"price_per_bathroom\"] = X[\"price_per_bathroom\"].map(lambda x: 100 if x>100 else x) # fix inf\n",
    "        X[\"price_per_bathroom\"].fillna(value=-1,inplace=True) # fix na\n",
    "       \n",
    "        #duplicates\n",
    "        X[\"photos_string\"] = X.photos.map(lambda x: ' '.join(x))\n",
    "        X[\"photos_duplicate\"] = X.duplicated(\"photos_string\",keep=False)\n",
    "        X[\"features_string\"] = X.photos.map(lambda x: ' '.join(x))\n",
    "        X[\"features_duplicate\"] = X.duplicated(\"features_string\",keep=False)\n",
    "        X[\"description_duplicate\"] = X.duplicated(\"description\",keep=False)\n",
    "        \n",
    "        # creation date\n",
    "        X.created = pd.to_datetime(X.created)\n",
    "        X[\"year\"] = X[\"created\"].dt.year\n",
    "        X[\"day\"] = X[\"created\"].dt.day\n",
    "        X[\"month\"] = X[\"created\"].dt.month\n",
    "        X[\"hour\"] = X[\"created\"].dt.hour\n",
    "        X[\"weekday\"] = X[\"created\"].dt.weekday\n",
    "        X[\"days_passed\"] = (X[\"created\"].max() - X[\"created\"]).dt.days\n",
    "        \n",
    "        \n",
    "        # zones\n",
    "        kmeans = KMeans(n_clusters=325, init='k-means++', n_init=10, max_iter=400,verbose=0, random_state=3, n_jobs=-1)\n",
    "        kmeans.fit_transform(X[[\"longitude\",\"latitude\"]])\n",
    "        X[\"kmeans\"] =  kmeans.labels_\n",
    "        \n",
    "        # drop\n",
    "        X.drop([\"created\",\"features\",\"photos\",\"photos_string\",\"description\",\"features_string\"], axis=1, inplace=True)\n",
    "        return X\n",
    "    \n",
    "class count_vector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"This custom tranformer select the features passes as the \n",
    "       argument attribute_names\"\"\"\n",
    "    \n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        vectorizer = CountVectorizer(min_df=1,stop_words='english')\n",
    "        corpus = X[self.attribute_names].map(lambda x: ' '.join(x))\n",
    "        cv = vectorizer.fit_transform(corpus)\n",
    "        return cv\n",
    "        \n",
    "        \n",
    "class tfidf_vector (BaseEstimator, TransformerMixin):\n",
    "    \"\"\"This custom tranformer select the features passes as the \n",
    "       argument attribute_names\"\"\"\n",
    "    \n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X[self.key] = X[self.key].apply(str)\n",
    "        stemmer = SnowballStemmer(\"english\",ignore_stopwords=True)\n",
    "        X[self.key] = X[self.key].apply(stemmer.stem)\n",
    "\n",
    "        tfidf = TfidfVectorizer(ngram_range=(1, 1), stop_words='english')   \n",
    "        tfidf_sparce = tfidf.fit_transform(X[self.key])\n",
    "        return tfidf_sparce\n",
    "             \n",
    "\n",
    "        \n",
    "class encode (BaseEstimator, TransformerMixin):\n",
    "    \"\"\"This custom tranformer select the features passes as the \n",
    "       argument attribute_names\"\"\"\n",
    "    \n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = X[self.attribute_names]\n",
    "        \n",
    "        encoder= LabelEncoder()\n",
    "        \n",
    "        X[\"building_id\"] =  encoder.fit_transform(X[\"building_id\"])\n",
    "        X[\"manager_id\"] =  encoder.fit_transform(X[\"manager_id\"])\n",
    "        X[\"display_address\"] =  encoder.fit_transform(X[\"display_address\"])\n",
    "        X[\"street_address\"] =  encoder.fit_transform(X[\"street_address\"])\n",
    "        \n",
    "        X[\"photos\"] = X.photos.map(lambda x: ' '.join(x))\n",
    "        X[\"photos\"] =  encoder.fit_transform(X[\"photos\"])\n",
    "       \n",
    "        \n",
    "        X[\"features\"] = X.features.map(lambda x: ' '.join(x))\n",
    "        X[\"features\"] =  encoder.fit_transform(X[\"features\"])\n",
    "        \n",
    "        \n",
    "        X[\"description\"] =  encoder.fit_transform(X[\"description\"])\n",
    "        \n",
    "        \n",
    "        return X       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 13)\n",
      "(74659, 13)\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "train_df = pd.read_json(\"./input/train.json\")\n",
    "test_df = pd.read_json(\"./input/test.json\")\n",
    "\n",
    "#drop columns that won't be used \n",
    "train_df.drop([\"listing_id\"],axis=1, inplace=True)\n",
    "y_test = test_df.listing_id.values\n",
    "test_df.drop([\"listing_id\"],axis=1, inplace=True)\n",
    "\n",
    "# encode target variable\n",
    "encoder_interest = LabelEncoder()\n",
    "y_train =  encoder_interest.fit_transform(train_df[\"interest_level\"])\n",
    "train_df.drop(\"interest_level\", axis=1,inplace=True)\n",
    "\n",
    "# feature categories\n",
    "fe_features = [\"bathrooms\", \"bedrooms\", \"latitude\", \"longitude\",\n",
    "               \"price\", \"features\", \"created\", \"photos\", \"description\"]\n",
    "encode_features = [\"building_id\", \"manager_id\",\"display_address\",\n",
    "                   \"photos\", \"features\",\"description\",\"street_address\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# truncated SVD for sparce matrix features\n",
    "tsvd_features = TruncatedSVD(n_components=40, random_state = 1)\n",
    "tsvd_description = TruncatedSVD(n_components=20, random_state = 1)\n",
    "\n",
    "#pipeline\n",
    "rent_pipeline = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "                transformer_list = [\n",
    "                    ('fe',  fe(fe_features)),\n",
    "                    ('encode',  encode(encode_features)),\n",
    "                    ('listing_feat_to_sparce', Pipeline([('count_vectorizer', count_vector(\"features\")),\n",
    "                                                         ('tsvd_features', tsvd_features)\n",
    "                                                        ])),\n",
    "                    ('tfidf_description', Pipeline([('tfidf', tfidf_vector(\"description\")),\n",
    "                                                    ('tsvd_desc', tsvd_description)\n",
    "                                                   ]))\n",
    "                ],\n",
    "                transformer_weights = {'fe':1.0,\n",
    "                                       'encode':1.0,\n",
    "                                       'listing_feat_to_sparce':1,\n",
    "                                       'tfidf_description':1\n",
    "                                      })\n",
    "        )])\n",
    "\n",
    "\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 93)\n",
      "(74659, 93)\n"
     ]
    }
   ],
   "source": [
    "# run pipeline\n",
    "rows_train = train_df.shape[0]\n",
    "all_df = pd.concat([train_df,test_df])\n",
    "X_all_df = pd.DataFrame(rent_pipeline.fit_transform(all_df))\n",
    "X_train = X_all_df.iloc[:49352]\n",
    "X_test = X_all_df.iloc[49352:]\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed: 22.7min remaining:  9.7min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 31.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ----------------- GRID_SEARCH INFO -----------------\n",
      " \n",
      "Best parameters:\n",
      "{'n_estimators': 525, 'min_samples_leaf': 4, 'learning_rate': 0.1, 'max_features': 0.7}\n",
      "\n",
      "Best estimator:\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=0.7, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=4,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=525, presort='auto', random_state=3,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "\n",
      "Best CV score: -0.564587261647\n",
      "\n",
      "All scores:\n",
      "[mean: -0.57470, std: 0.00388, params: {'n_estimators': 525, 'min_samples_leaf': 4, 'learning_rate': 0.1, 'max_features': 'sqrt'}, mean: -0.56459, std: 0.00423, params: {'n_estimators': 525, 'min_samples_leaf': 4, 'learning_rate': 0.1, 'max_features': 0.7}]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl8AAAC/CAYAAADAZLm2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a08a898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model GB -gridsearch\n",
    "param_grid = [{'n_estimators': [525], 'max_features': ['sqrt',0.7],\n",
    "               'learning_rate': [0.1], 'min_samples_leaf':[4]}]\n",
    "\n",
    "gbc = GradientBoostingClassifier(random_state=3)\n",
    "grid_search = GridSearchCV(gbc, param_grid, cv=5,\n",
    "                           scoring='neg_log_loss',\n",
    "                           n_jobs=-1,\n",
    "                           verbose=3)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\" ----------------- GRID_SEARCH INFO -----------------\\n \")\n",
    "print(\"Best parameters:\")\n",
    "print(grid_search.best_params_)\n",
    "print(\"\\nBest estimator:\")\n",
    "print(grid_search.best_estimator_)\n",
    "print(\"\\nBest CV score:\", grid_search.best_score_)\n",
    "print(\"\\nAll scores:\")\n",
    "print(grid_search.grid_scores_)\n",
    "\n",
    "# submission\n",
    "final_model = grid_search.best_estimator_\n",
    "# predictions\n",
    "final_predictions = final_model.predict_proba(X_test)\n",
    "# sub\n",
    "pd.DataFrame({'listing_id':y_test,\n",
    "              'high':final_predictions[:,0],\n",
    "              'medium':final_predictions[:,2],\n",
    "              'low': final_predictions[:,1]}).to_csv(\"./submissions/subgb1.csv\",index=False)\n",
    "\n",
    "# plot probs\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax1 = plt.subplot2grid((3, 1), (2, 0))\n",
    "ax1.hist(final_predictions[:,0], range=(0, 1), bins=10, label=\"tst\",\n",
    "             histtype=\"step\", lw=2, color=\"red\")\n",
    "ax1.hist(final_predictions[:,1], range=(0, 1), bins=10, label=\"tst\",\n",
    "             histtype=\"step\", lw=2)\n",
    "ax1.hist(final_predictions[:,2], range=(0, 1), bins=10, label=\"tst\",\n",
    "             histtype=\"step\", lw=2)\n",
    "# legend\n",
    "import matplotlib.patches as mpatches\n",
    "pink_patch = mpatches.Patch(color='red', label='high')\n",
    "green_patch = mpatches.Patch(color='blue', label='low')\n",
    "blue_patch = mpatches.Patch(color='green', label='medium')\n",
    "plt.legend(handles=[pink_patch,green_patch,blue_patch])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eclf = VotingClassifier(estimators=[('rf1', rf1), ('rf2', rf2), ('gbc', gbc), ('xgb',xgb)], voting='soft')\n",
    "eclf.fit(X_train, y_train)\n",
    "y_val_pred = eclf.predict_proba(X_val)\n",
    "log_loss(y_val, y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid = [{'n_estimators': [500], 'max_features': ['sqrt'],\n",
    "               'bootstrap': [True], 'min_samples_leaf':[5]}]\n",
    "\n",
    "forest_clas = RandomForestClassifier(random_state=3)\n",
    "grid_search = GridSearchCV(forest_clas, param_grid, cv=5,\n",
    "                           scoring='neg_log_loss',\n",
    "                           n_jobs=-1,\n",
    "                           verbose=3)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\" ----------------- GRID_SEARCH INFO -----------------\\n \")\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_estimator_)\n",
    "print(\"Best CV score:\", grid_search.best_score_)\n",
    "print(grid_search.grid_scores_)\n",
    "               \n",
    "# test set\n",
    "#X_test = rent_pipeline.fit_transform(test_df)\n",
    "# submission\n",
    "final_model = grid_search.best_estimator_\n",
    "# predictions\n",
    "final_predictions = final_model.predict_proba(X_test)\n",
    "# sub\n",
    "pd.DataFrame({'listing_id':test_df.listing_id.values,\n",
    "              'high':final_predictions[:,0],\n",
    "              'medium':final_predictions[:,2],\n",
    "              'low': final_predictions[:,1]}).to_csv(\"./submissions/subrf.csv\",index=False)\n",
    "\n",
    "# plot probs\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax1 = plt.subplot2grid((3, 1), (2, 0))\n",
    "ax1.hist(final_predictions[:,0], range=(0, 1), bins=10, label=\"tst\",\n",
    "             histtype=\"step\", lw=2, color=\"red\")\n",
    "ax1.hist(final_predictions[:,1], range=(0, 1), bins=10, label=\"tst\",\n",
    "             histtype=\"step\", lw=2)\n",
    "ax1.hist(final_predictions[:,2], range=(0, 1), bins=10, label=\"tst\",\n",
    "             histtype=\"step\", lw=2)\n",
    "# legend\n",
    "import matplotlib.patches as mpatches\n",
    "pink_patch = mpatches.Patch(color='red', label='high')\n",
    "green_patch = mpatches.Patch(color='blue', label='low')\n",
    "blue_patch = mpatches.Patch(color='green', label='medium')\n",
    "plt.legend(handles=[pink_patch,green_patch,blue_patch])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# feature importance\n",
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "indices = np.argsort(feature_importances)[::-1]\n",
    "attributes = X_train.columns\n",
    "fimpotances = sorted(zip(feature_importances, attributes), reverse=True)\n",
    "\n",
    "# plot 15 most important features \n",
    "plt.figure(figsize=(8, 15))\n",
    "plt.barh(range(len(fimpotances)), feature_importances[indices], color=\"r\", align=\"center\")\n",
    "plt.yticks(range(len(fimpotances)), [x[1] for x in fimpotances])\n",
    "plt.title(\"Feature importances\", size=20)\n",
    "plt.grid(True)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test set\n",
    "X_test = rent_pipeline.fit_transform(test_df)\n",
    "# submission\n",
    "final_model = grid_search.best_estimator_\n",
    "# predictions\n",
    "final_predictions = final_model.predict_proba(X_test)\n",
    "# sub\n",
    "pd.DataFrame({'listing_id':test_df.listing_id.values,\n",
    "              'high':final_predictions[:,0],\n",
    "              'medium':final_predictions[:,2],\n",
    "              'low': final_predictions[:,1]}).to_csv(\"./submissions/sub.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.cm as cm\n",
    "import pandas as pd\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_df = pd.read_json(\"./input/train.json\")\n",
    "\n",
    "west, south, east, north = -74.05, 40.60, -73.80, 40.90\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(22,27))\n",
    "\n",
    "kmeans = KMeans(n_clusters=500, init='k-means++', n_init=10, max_iter=300,verbose=0, random_state=3, n_jobs=-1)\n",
    "kmeans.fit_transform(train_df[[\"longitude\",\"latitude\"]])\n",
    "train_df[\"kmeans\"] =  kmeans.labels_\n",
    "\n",
    "fig.add_subplot(222)\n",
    "\n",
    "colors = cm.rainbow(np.linspace(0, 1, 500))\n",
    "\n",
    "m = Basemap(llcrnrlat=south, urcrnrlat=north, llcrnrlon=west,\n",
    "            urcrnrlon=east, lat_ts=south,resolution='i')\n",
    "\n",
    "c=0\n",
    "for k in train_df[\"kmeans\"].unique():\n",
    "    \n",
    "    aa = train_df[train_df[\"kmeans\"] == k]\n",
    "    m.plot(aa['longitude'].values,aa['latitude'].values,\n",
    "       'bo', \n",
    "       markersize=2, color=colors[c],alpha=0.3,\n",
    "       markeredgewidth=0.05) \n",
    "    c=c+1\n",
    "\n",
    "m.drawmapboundary(fill_color='black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax1 = plt.subplot2grid((3, 1), (2, 0))\n",
    "ax1.hist(final_predictions[:,0], range=(0, 1), bins=10, label=\"tst\",\n",
    "             histtype=\"step\", lw=2, color=\"red\")\n",
    "ax1.hist(final_predictions[:,1], range=(0, 1), bins=10, label=\"tst\",\n",
    "             histtype=\"step\", lw=2)\n",
    "ax1.hist(final_predictions[:,2], range=(0, 1), bins=10, label=\"tst\",\n",
    "             histtype=\"step\", lw=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# Gaussian Naive-Bayes with isotonic calibration\n",
    "clf_isotonic = CalibratedClassifierCV(final_model, cv=2, method='isotonic')\n",
    "clf_isotonic.fit(X_train, y_train)\n",
    "prob_pos_isotonic = clf_isotonic.predict_proba(X_test)\n",
    "\n",
    "# Gaussian Naive-Bayes with sigmoid calibration\n",
    "clf_sigmoid = CalibratedClassifierCV(final_model, cv=2, method='sigmoid')\n",
    "clf_sigmoid.fit(X_train, y_train)\n",
    "prob_pos_sigmoid = clf_sigmoid.predict_proba(X_test)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax1 = plt.subplot2grid((3, 1), (2, 0))\n",
    "ax1.hist(final_predictions[:,0], range=(0, 1), bins=10, label=\"tst\",\n",
    "             histtype=\"step\", lw=2, color=\"red\")\n",
    "ax1.hist(final_predictions[:,1], range=(0, 1), bins=10, label=\"tst\",\n",
    "             histtype=\"step\", lw=2)\n",
    "ax1.hist(final_predictions[:,2], range=(0, 1), bins=10, label=\"tst\",\n",
    "             histtype=\"step\", lw=2)\n",
    "ax1.set_ylim([0,65000])\n",
    "plt.title(\"Normal\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax1 = plt.subplot2grid((3, 1), (2, 0))\n",
    "ax1.hist(prob_pos_sigmoid[:,0], range=(0, 1), bins=10, label=\"tst\",\n",
    "             histtype=\"step\", lw=2, color=\"red\")\n",
    "ax1.hist(prob_pos_sigmoid[:,1], range=(0, 1), bins=10, label=\"tst\",\n",
    "             histtype=\"step\", lw=2)\n",
    "ax1.hist(prob_pos_sigmoid[:,2], range=(0, 1), bins=10, label=\"tst\",\n",
    "             histtype=\"step\", lw=2)\n",
    "ax1.set_ylim([0,65000])\n",
    "plt.title(\"Sigmoid\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax1 = plt.subplot2grid((3, 1), (2, 0))\n",
    "ax1.hist(prob_pos_isotonic[:,0], range=(0, 1), bins=10, label=\"tst\",\n",
    "             histtype=\"step\", lw=2, color=\"red\")\n",
    "ax1.hist(prob_pos_isotonic[:,1], range=(0, 1), bins=10, label=\"tst\",\n",
    "             histtype=\"step\", lw=2)\n",
    "ax1.hist(prob_pos_isotonic[:,2], range=(0, 1), bins=10, label=\"tst\",\n",
    "             histtype=\"step\", lw=2)\n",
    "ax1.set_ylim([0,65000])\n",
    "plt.title(\"Isitonic\")\n",
    "plt.show()\n",
    "\n",
    "pd.DataFrame({'listing_id':test_df.listing_id.values,\n",
    "              'high':prob_pos_sigmoid[:,0],\n",
    "              'medium':prob_pos_sigmoid[:,2],\n",
    "              'low': prob_pos_sigmoid[:,1]}).to_csv(\"./submissions/prob_pos_sigmoid.csv\",index=False)\n",
    "pd.DataFrame({'listing_id':test_df.listing_id.values,\n",
    "              'high':prob_pos_sigmoid[:,0],\n",
    "              'medium':prob_pos_sigmoid[:,2],\n",
    "              'low': prob_pos_isotonic[:,1]}).to_csv(\"./submissions/prob_pos_isotonic.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "tsvd_features = TruncatedSVD(n_components=40, random_state = 1)\n",
    "\n",
    "tsvd_description = TruncatedSVD(n_components=20, random_state = 1)\n",
    "\n",
    "Best parameters:\n",
    "{'n_estimators': 525, 'min_samples_leaf': 4, 'learning_rate': 0.1, 'max_features': 0.7}\n",
    "\n",
    "Best estimator:\n",
    "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
    "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
    "              max_features=0.7, max_leaf_nodes=None,\n",
    "              min_impurity_split=1e-07, min_samples_leaf=4,\n",
    "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "              n_estimators=525, presort='auto', random_state=3,\n",
    "              subsample=1.0, verbose=0, warm_start=False)\n",
    "\n",
    "Best CV score: -0.564587261647 - LB:0.56973"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
